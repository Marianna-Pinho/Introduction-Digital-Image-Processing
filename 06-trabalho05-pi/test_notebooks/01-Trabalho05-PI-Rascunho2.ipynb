{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Trabalho 05 - Introdução ao Processamento de Imagem Digital </center>\n",
    "\n",
    "**Aluna:** Marianna de Pinho Severo <br>\n",
    "**RA**: 264960 <br>\n",
    "**Professor:** Hélio Pedrini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 01: Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAllImages(images, labels):\n",
    "    columns = 2\n",
    "    rows = 3\n",
    "    i = 1\n",
    "    fig=plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    for image,label in zip(images,labels):\n",
    "        print(type(image[0,0]))\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.xlabel(label)\n",
    "        plt.imshow(image)\n",
    "        i = i+1\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.40, top=0.75)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 02: Ler imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "images['building1'] = cv.imread('input_images/foto1A.jpg')\n",
    "images['building2'] = cv.imread('input_images/foto1B.jpg')\n",
    "images['lake1'] = cv.imread('input_images/foto2A.jpg')\n",
    "images['lake2'] = cv.imread('input_images/foto2B.jpg')\n",
    "images['road1'] = cv.imread('input_images/foto3B.jpg')\n",
    "images['road2'] = cv.imread('input_images/foto3A.jpg')\n",
    "images['desertroad1'] = cv.imread('input_images/foto4B.jpg')\n",
    "images['desertroad2'] = cv.imread('input_images/foto4A.jpg')\n",
    "images['field1'] = cv.imread('input_images/foto5A.jpg')\n",
    "images['field2'] = cv.imread('input_images/foto5B.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 03: Converter imagens para a escala de cinza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in images:\n",
    "    gray_images[key] = cv.cvtColor(images[key], cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.imshow('teste', gray_images['building1'])\n",
    "# cv.waitKey(0)\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 03: Encontrar pontos de interesse e descritores invariantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_keys = list(gray_images.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 3.1: ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_keypoints = {}\n",
    "orb_descriptors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv.ORB_create()\n",
    "pos = 0\n",
    "while pos < len(image_keys):\n",
    "    img1 = gray_images[image_keys[pos]]\n",
    "    img2 = gray_images[image_keys[pos+1]]\n",
    "        \n",
    "    orb_keypoints[image_keys[pos]], orb_descriptors[image_keys[pos]] = orb.detectAndCompute(img1,None)\n",
    "    orb_keypoints[image_keys[pos+1]], orb_descriptors[image_keys[pos+1]] = orb.detectAndCompute(img2,None)\n",
    "    \n",
    "    pos+=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Passo 3.2: BRIEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_keypoints = {}\n",
    "brief_descriptors = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "star = cv.xfeatures2d.StarDetector_create()\n",
    "brief = cv.xfeatures2d.BriefDescriptorExtractor_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 0\n",
    "while pos < len(image_keys):\n",
    "    img1 = gray_images[image_keys[pos]]\n",
    "    img2 = gray_images[image_keys[pos+1]]\n",
    "    \n",
    "    brief_keypoints[image_keys[pos]] = orb.detect(img1,None) #star doesn't find interest points for field1 and field2\n",
    "    brief_keypoints[image_keys[pos+1]] = orb.detect(img2,None)\n",
    "    \n",
    "    brief_keypoints[image_keys[pos]], brief_descriptors[image_keys[pos]] = brief.compute(img1, brief_keypoints[image_keys[pos]])\n",
    "    brief_keypoints[image_keys[pos+1]], brief_descriptors[image_keys[pos+1]] = brief.compute(img2, brief_keypoints[image_keys[pos+1]])\n",
    "    \n",
    "    pos +=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 04: Encontrar similaridades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa função retorna apenas os matches cuja correspondências entre descritores for maior do que um determinado limiar. Como não sabemos a maior distância possível entre dois descritores, utilizamos a máxima distância obtida entre os matches. Então, normalizamos o vetor de distâncias por esse máximo e subtraímos de um. Assim, quanto maior for esse resultado, menor vai ser a distância entre dois descritores, com relação à maior distância obtida e, não, à maior distância possível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorrespondingMatches(matches, corr_level=0.5):\n",
    "    if matches == []:\n",
    "        return []\n",
    "    \n",
    "    distances = [m.distance for m in matches]\n",
    "    distances = distances/np.max(distances)\n",
    "    \n",
    "    corr_values = np.ones((1,len(distances))) - distances\n",
    "    corr_indexes = np.where(corr_values >= corr_level)[1]\n",
    "    \n",
    "    corresponding = [matches[idx] for idx in corr_indexes]\n",
    "    \n",
    "    return corresponding if len(corresponding) > 0 else matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_matches = {}\n",
    "brief_matches = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_force = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brute_force = cv.DescriptorMatcher_create(cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 0\n",
    "while pos < len(image_keys):\n",
    "    key1 = image_keys[pos]\n",
    "    key2 = image_keys[pos+1]\n",
    "    \n",
    "    orb_matches[key1+ '_'+key2] = brute_force.match(orb_descriptors[key1],orb_descriptors[key2])\n",
    "    orb_matches[key1+ '_'+key2] = sorted(orb_matches[key1+ '_'+key2], key = lambda x:x.distance)\n",
    "    orb_matches[key1+ '_'+key2] = getCorrespondingMatches(orb_matches[key1+ '_'+key2],0.3)\n",
    "    \n",
    "    brief_matches[key1+ '_'+key2] = brute_force.match(brief_descriptors[key1],brief_descriptors[key2])\n",
    "    brief_matches[key1+ '_'+key2] = sorted(brief_matches[key1+ '_'+key2], key = lambda x:x.distance)\n",
    "    brief_matches[key1+ '_'+key2] = getCorrespondingMatches(brief_matches[key1+ '_'+key2])\n",
    "    \n",
    "    pos+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Draw first 10 matches.\n",
    "# plt.figure(figsize=(10,10))\n",
    "# imMatches = cv.drawMatches(gray_images['desert_road1'], orb_keypoints['desert_road1'],gray_images['desert_road2'], orb_keypoints['desert_road2'], orb_matches['desert_road1_desert_road2'], None)\n",
    "# plt.imshow(imMatches),plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 05: Estimar matriz de homografia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_homography_matrix = {}\n",
    "brief_homography_matrix = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in orb_matches:\n",
    "    points1 = np.zeros((len(orb_matches[key]), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(orb_matches[key]), 2), dtype=np.float32)\n",
    "    \n",
    "    if len(orb_matches[key])>=4:\n",
    "        for i, match in enumerate(orb_matches[key]):\n",
    "            subkey1,subkey2 = key.split('_')\n",
    "\n",
    "            points1[i, :] = (orb_keypoints[subkey1])[match.queryIdx].pt\n",
    "            points2[i, :] = (orb_keypoints[subkey2])[match.trainIdx].pt\n",
    "\n",
    "        orb_homography_matrix[key], mask = cv.findHomography(points1, points2, cv.RANSAC)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in brief_matches:\n",
    "    points1 = np.zeros((len(brief_matches[key]), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(brief_matches[key]), 2), dtype=np.float32)\n",
    "    \n",
    "    if len(brief_matches[key])>=4:\n",
    "        for i, match in enumerate(brief_matches[key]):\n",
    "            subkey1,subkey2 = key.split('_')\n",
    "\n",
    "            points1[i, :] = (brief_keypoints[subkey1])[match.queryIdx].pt\n",
    "            points2[i, :] = (brief_keypoints[subkey2])[match.trainIdx].pt\n",
    "\n",
    "        brief_homography_matrix[key], mask = cv.findHomography(points1, points2, cv.RANSAC,5.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:building1_building2\n",
      "[[ 8.10030703e-01  1.10831200e-01  4.28237400e+02]\n",
      " [-1.34127332e-01  9.93500367e-01  5.75715582e+01]\n",
      " [-2.09447284e-04  5.15296111e-05  1.00000000e+00]]\n",
      "key:lake1_lake2\n",
      "[[ 1.00175598e+00  5.90324781e-05  4.62964699e+02]\n",
      " [-6.05475729e-05  1.00122197e+00 -8.71878025e-02]\n",
      " [ 1.99085720e-06  1.05295372e-06  1.00000000e+00]]\n",
      "key:road1_road2\n",
      "[[ 1.00016778e+00  2.13712076e-02 -2.99192385e+01]\n",
      " [-2.01675244e-02  1.01476959e+00  1.32684758e+02]\n",
      " [-1.51295903e-05  4.72223175e-05  1.00000000e+00]]\n",
      "key:desertroad1_desertroad2\n",
      "[[-4.71491007e-01 -2.64025257e-01  1.83256439e+02]\n",
      " [-6.01186760e-01 -4.05202167e-01  2.52128383e+02]\n",
      " [-2.39345797e-03 -1.60457853e-03  1.00000000e+00]]\n",
      "key:field1_field2\n",
      "[[ 1.66804304e+00 -1.60574596e-01 -3.81870061e+01]\n",
      " [ 4.15689801e-01  1.08436980e+00  5.06288649e+01]\n",
      " [ 8.88913588e-04 -1.08570049e-04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "for key in brief_homography_matrix:\n",
    "    print(\"key:{}\\n{}\".format(key, brief_homography_matrix[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key:building1_building2\n",
      "[[ 8.17948533e-01  1.24347475e-01  4.24088834e+02]\n",
      " [-1.33492861e-01  1.00166942e+00  5.65667993e+01]\n",
      " [-2.06849224e-04  6.27661732e-05  1.00000000e+00]]\n",
      "key:lake1_lake2\n",
      "[[ 9.94820349e-01  4.86939747e-04  4.63132833e+02]\n",
      " [-5.75531434e-04  9.99917525e-01  2.98149574e-02]\n",
      " [-5.69777271e-06  1.37462067e-06  1.00000000e+00]]\n",
      "key:road1_road2\n",
      "[[ 1.00611333e+00  2.55983645e-02 -3.09871534e+01]\n",
      " [-1.80572177e-02  1.02484832e+00  1.31902495e+02]\n",
      " [-6.36002536e-06  6.03680923e-05  1.00000000e+00]]\n",
      "key:desertroad1_desertroad2\n",
      "[[ 4.31838750e-01 -4.37816978e-01  1.94874440e+02]\n",
      " [ 4.14354519e-01  4.34967359e-01  2.46995734e+00]\n",
      " [-4.04824451e-05 -5.16501417e-05  1.00000000e+00]]\n",
      "key:field1_field2\n",
      "[[ 9.56485606e-01 -7.39491441e-02  4.42703442e+01]\n",
      " [ 4.90152164e-02  9.58158146e-01  9.53033313e+01]\n",
      " [-3.02035118e-05 -6.02380853e-05  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "for key in orb_homography_matrix:\n",
    "    print(\"key:{}\\n{}\".format(key, orb_homography_matrix[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 06: Alinhar imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "orb_panoramic_images = {}\n",
    "brief_panoramic_images = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in orb_homography_matrix:\n",
    "    subkey1,subkey2 = key.split('_')\n",
    "    \n",
    "    img1 = images[subkey1]\n",
    "    img2 = images[subkey2]\n",
    "    \n",
    "    height, width,deep = img2.shape\n",
    "    orb_panoramic_images[key] = cv.warpPerspective(img1, orb_homography_matrix[key], (width+img1.shape[1], height+img1.shape[0]))\n",
    "    (orb_panoramic_images[key])[:img2.shape[0],:img2.shape[1]] = img2\n",
    "    \n",
    "    brief_panoramic_images[key] = cv.warpPerspective(img1, brief_homography_matrix[key], (width+img1.shape[1], height+img1.shape[0]))\n",
    "    (brief_panoramic_images[key])[:img2.shape[0],:img2.shape[1]] = img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in brief_panoramic_images:\n",
    "#     plt.imshow(brief_panoramic_images[key],)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 07: Salvar imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in orb_panoramic_images:\n",
    "    cv.imwrite('output_images/orb_'+key+'.png', orb_panoramic_images[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in brief_panoramic_images:\n",
    "    cv.imwrite('output_images/brief_'+key+'.png', brief_panoramic_images[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
